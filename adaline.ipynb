{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bored-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "restricted-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_1 = pd.DataFrame({\n",
    "    'x1': np.random.normal(1, .5, 1000), \n",
    "    'x2': np.random.normal(1, .5, 1000), \n",
    "    'y': 1\n",
    "})\n",
    "data1_2 = pd.DataFrame({\n",
    "    'x1': np.random.normal(-1, .5, 10), \n",
    "    'x2': np.random.normal(-1, .5, 10), \n",
    "    'y': -1\n",
    "})\n",
    "data2_1 = pd.DataFrame({\n",
    "    'x1': np.random.normal(1, .5, 100), \n",
    "    'x2': np.random.normal(1, .5, 100), \n",
    "    'y': 1\n",
    "})\n",
    "data2_2 = pd.DataFrame({\n",
    "    'x1': np.random.normal(-1, .5, 100), \n",
    "    'x2': np.random.normal(-1, .5, 100), \n",
    "    'y': -1\n",
    "})\n",
    "data1_df = pd.concat([data1_1, data1_2], axis=0).reset_index(drop=True)\n",
    "data2_df = pd.concat([data2_1, data2_2], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "alternate-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(inputs, W):\n",
    "    net = np.dot(inputs, W[:-1]) + W[-1]\n",
    "    if net >= 0:\n",
    "        h = 1\n",
    "    else:\n",
    "        h = -1\n",
    "    return net, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "modular-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_tanh(inputs, W):\n",
    "    net = np.dot(inputs, W[:-1]) + W[-1]\n",
    "    h = np.tanh(net)\n",
    "    return net, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "insured-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_perceptron(X_train, y_train, gradient=False, max_epochs = 100):\n",
    "#     lamda = .001\n",
    "#     W = np.zeros(X_train.shape[1] + 1)\n",
    "#     lr = .001\n",
    "#     epochs = 0\n",
    "#     while True:\n",
    "#         errors = []\n",
    "#         epochs += 1\n",
    "#         for index in X_train.index:\n",
    "#             net, h = forward_pass(X_train.loc[index], W)\n",
    "#             if gradient:\n",
    "#                 error = .5*(y_train.loc[index] - np.tanh(lamda*net)) ** 2\n",
    "#             else:\n",
    "#                 error = y_train.loc[index] - net\n",
    "#             errors.append(error)\n",
    "#             if gradient:\n",
    "#                 W[:-1] += lr*(1 - h**2)*lamda*(y_train.loc[index] - h)*X_train.loc[index]\n",
    "#                 W[-1] += lr*(1 - h**2)*lamda*(y_train.loc[index] - h)\n",
    "#             else:  \n",
    "#                 W[:-1] += lr*error*X_train.loc[index]\n",
    "#                 W[-1] += lr*error\n",
    "#         if not any(errors) or epochs > max_epochs:\n",
    "#             break\n",
    "#         if epochs % 10 == 0:\n",
    "#             print('epoch: {}'.format(epochs))\n",
    "#             print('sum of errors: {}'.format(sum(errors)))\n",
    "#     return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "several-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(X_train, y_train, max_epochs = 100, gradient=False):\n",
    "    lamda = .01\n",
    "    W = np.zeros(X_train.shape[1] + 1)\n",
    "    lr = .001\n",
    "    epochs = 1\n",
    "    while True:\n",
    "        errors = []\n",
    "        epochs += 1\n",
    "        for index in X_train.index:\n",
    "            net, h = forward_pass(X_train.loc[index], W)\n",
    "            if gradient:\n",
    "                error = .5*(y_train.loc[index] - np.tanh(lamda*net)) ** 2\n",
    "            else:\n",
    "                error = y_train.loc[index] - net\n",
    "            errors.append(error)\n",
    "            if gradient:\n",
    "                W[:-1] += lr*(1 - h**2)*lamda*(y_train.loc[index] - h)*X_train.loc[index]\n",
    "                W[-1] += lr*(1 - h**2)*lamda*(y_train.loc[index] - h)\n",
    "            else:  \n",
    "                W[:-1] += lr*error*X_train.loc[index]\n",
    "                W[-1] += lr*error\n",
    "        if not any(errors) or epochs > max_epochs:\n",
    "            break\n",
    "        if epochs % 10 == 0:\n",
    "            print('epoch: {}'.format(epochs))\n",
    "            print('sum of errors: {}'.format(sum(errors)))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "saving-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dividing_lines(x, y, ax, points):\n",
    "    sns.scatterplot(data=points, x='x1', y='x2', alpha=0.8, hue='y', palette='flare', ax=ax)\n",
    "    sns.lineplot(x=x, y=y, color='black', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "excessive-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dividing_line(X_train, y_train, df, max_epochs, gradient):\n",
    "    W = train_perceptron(X_train, y_train, max_epochs=100, gradient=gradient)\n",
    "    x1_min, x1_max = min(df['x1']), max(df['x1'])\n",
    "    x = np.linspace(x1_min, x1_max, num=10000)\n",
    "    y = (-W[0]*x - W[-1]) / W[1]\n",
    "    return W, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "attractive-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_misclassifieds(W, X_train, y_train):\n",
    "    misclassified_indices = []\n",
    "    for index in X_train.index:\n",
    "        net, h = forward_pass(X_train.loc[index], W)\n",
    "        if h != y_train.loc[index]:\n",
    "            misclassified_indices.append(index)\n",
    "    return misclassified_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-diamond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\n",
      "sum of errors: 19.163559219383824\n",
      "epoch: 20\n",
      "sum of errors: 6.564025591606031\n",
      "epoch: 30\n",
      "sum of errors: 2.2499356166226523\n",
      "epoch: 40\n",
      "sum of errors: 0.7713065617882284\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15, 8))\n",
    "for ax_index, data_df in enumerate([data1_df, data2_df]):\n",
    "    X_train = data_df[['x1', 'x2']]\n",
    "    y_train = data_df['y']\n",
    "    W, x, y = find_dividing_line(X_train, y_train, data_df, max_epochs=100, gradient=False)\n",
    "    ax = plt.subplot(1, 2, ax_index + 1)\n",
    "    misclassified_indices = find_misclassifieds(W, X_train, y_train)\n",
    "    plot_dividing_lines(x, y, ax, data_df)\n",
    "    if len(misclassified_indices):\n",
    "        sns.scatterplot(data=X_train.loc[misclassified_indices], x='x1', y='x2', ax=ax, color='red', label='misclassified points')\n",
    "    ax.set_title('with {} misclassified points - accuracy {}'\n",
    "                 .format(\n",
    "                     len(misclassified_indices), (X_train.shape[0] - len(misclassified_indices)) / X_train.shape[0])\n",
    "                )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 8))\n",
    "for ax_index, data_df in enumerate([data1_df, data2_df]):\n",
    "    X_train = data_df[['x1', 'x2']]\n",
    "    y_train = data_df['y']\n",
    "    W, x, y = find_dividing_line(X_train, y_train, data_df, gradient=True)\n",
    "    ax = plt.subplot(1, 2, ax_index + 1)\n",
    "    misclassified_indices = find_misclassifieds(W, X_train, y_train)\n",
    "    plot_dividing_lines(x, y, ax, data_df)\n",
    "    if len(misclassified_indices):\n",
    "        sns.scatterplot(data=X_train.loc[misclassified_indices], x='x1', y='x2', ax=ax, color='red', label='misclassified points')\n",
    "    ax.set_title('with {} misclassified points - accuracy {}'\n",
    "                 .format(\n",
    "                     len(misclassified_indices), (X_train.shape[0] - len(misclassified_indices)) / X_train.shape[0])\n",
    "                )\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
