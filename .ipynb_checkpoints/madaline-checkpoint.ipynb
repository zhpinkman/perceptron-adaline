{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bored-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hawaiian-liabilities",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNDL-HW1.pdf             linear-perceptron.ipynb  perceptron.csv\r\n",
      "README.md                madaline.csv\r\n",
      "adaline.ipynb            madaline.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "restricted-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('madaline.csv', names=['x1', 'x2', 'y'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "placed-wiring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.459694</td>\n",
       "      <td>-0.470583</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.797385</td>\n",
       "      <td>-0.343030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.235270</td>\n",
       "      <td>0.961296</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2    y\n",
       "0  0.459694 -0.470583  0.0\n",
       "1  0.797385 -0.343030  0.0\n",
       "2  0.235270  0.961296  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swedish-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_neuron(inputs):\n",
    "    net = np.sum(inputs) - len(inputs) - .5\n",
    "    if net >= 0:\n",
    "        h = 1\n",
    "    else: \n",
    "        h = -1\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "modular-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass_tanh(inputs, W, lamda):\n",
    "    net = np.dot(inputs, W[:-1]) + W[-1]\n",
    "    h = np.tanh(net, lamda)\n",
    "    return net, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "several-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(X_train, y_train, gradient, max_epochs, n_neurons):\n",
    "    lamda = 1\n",
    "    W = np.zeros((n_neurons, X_train.shape[1]))\n",
    "    lr = .001\n",
    "    epochs = 1\n",
    "    while True:\n",
    "        errors = []\n",
    "        epochs += 1\n",
    "        for index in X_train.index:\n",
    "            if gradient:\n",
    "                net, h = forward_pass_tanh(X_train.loc[index], W, lamda)\n",
    "                error = 0.5*(y_train.loc[index] - np.tanh(lamda*net)) ** 2\n",
    "                W[:-1] += lr*(1 - h**2)*lamda*(y_train.loc[index] - h)*X_train.loc[index]\n",
    "                W[-1] += lr*(1 - h**2)*lamda*(y_train.loc[index] - h)\n",
    "\n",
    "            else:\n",
    "                net, h = forward_pass(X_train.loc[index], W)\n",
    "                error = y_train.loc[index] - net\n",
    "                W[:-1] += lr*error*X_train.loc[index]\n",
    "                W[-1] += lr*error\n",
    "                \n",
    "                \n",
    "            errors.append(error)\n",
    "\n",
    "\n",
    "        if not any(errors) or epochs > max_epochs:\n",
    "            break\n",
    "        if epochs % 10 == 0:\n",
    "            print('epoch: {}'.format(epochs))\n",
    "            print('sum of errors: {}'.format(sum(errors)))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "saving-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dividing_lines(x, y, ax, points):\n",
    "    sns.scatterplot(data=points, x='x1', y='x2', alpha=0.8, hue='y', palette='flare', ax=ax)\n",
    "    sns.lineplot(x=x, y=y, color='black', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "excessive-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dividing_line(X_train, y_train, df, gradient, max_epochs, n_neurons):\n",
    "    W = train_perceptron(X_train, y_train, gradient, max_epochs, n_neurons)\n",
    "    x1_min, x1_max = min(df['x1']), max(df['x1'])\n",
    "    x = np.linspace(x1_min, x1_max, num=10000)\n",
    "    y = (-W[0]*x - W[-1]) / W[1]\n",
    "    return W, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attractive-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_misclassifieds(W, X_train, y_train):\n",
    "    misclassified_indices = []\n",
    "    for index in X_train.index:\n",
    "        net, h = forward_pass(X_train.loc[index], W)\n",
    "        if h != y_train.loc[index]:\n",
    "            misclassified_indices.append(index)\n",
    "    return misclassified_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cutting-rochester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15, 8))\n",
    "X_train = df[['x1', 'x2']]\n",
    "y_train = df['y']\n",
    "W, x, y = find_dividing_line(X_train, y_train, df, True, 100, 3)\n",
    "ax = plt.subplot(1, 2, ax_index + 1)\n",
    "misclassified_indices = find_misclassifieds(W, X_train, y_train)\n",
    "plot_dividing_lines(x, y, ax, df)\n",
    "if len(misclassified_indices):\n",
    "    sns.scatterplot(data=X_train.loc[misclassified_indices], x='x1', y='x2', ax=ax, color='red', label='misclassified points')\n",
    "ax.set_title('with {} misclassified points - accuracy {}'\n",
    "             .format(\n",
    "                 len(misclassified_indices), (X_train.shape[0] - len(misclassified_indices)) / X_train.shape[0])\n",
    "            )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda = 1\n",
    "    W = np.zeros((n_neurons, X_train.shape[1]))\n",
    "    lr = .001\n",
    "    epochs = 1\n",
    "    for i in range(1):\n",
    "        errors = []\n",
    "        epochs += 1\n",
    "        for index in X_train.index:\n",
    "\n",
    "\n",
    "            net = np.dot(inputs, W[:-1]) + W[-1]\n",
    "            h = np.tanh(net, lamda)\n",
    "\n",
    "            error = 0.5*(y_train.loc[index] - np.tanh(lamda*net)) ** 2\n",
    "            W[:-1] += lr*(1 - h**2)*lamda*(y_train.loc[index] - h)*X_train.loc[index]\n",
    "            W[-1] += lr*(1 - h**2)*lamda*(y_train.loc[index] - h)\n",
    "\n",
    "                \n",
    "                \n",
    "            errors.append(error)\n",
    "\n",
    "\n",
    "        if not any(errors) or epochs > max_epochs:\n",
    "            break\n",
    "        if epochs % 10 == 0:\n",
    "            print('epoch: {}'.format(epochs))\n",
    "            print('sum of errors: {}'.format(sum(errors)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
